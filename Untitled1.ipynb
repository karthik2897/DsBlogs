{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb953039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Retrived\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import urllib\n",
    "import sqlalchemy as sa\n",
    "import pyodbc\n",
    "#Reading Data From Path\n",
    "df=pd.read_excel(r'C:\\Users\\A803377\\OneDrive - Solenis LLC\\Documents\\TREK-All-Learners.xlsx')\n",
    "df1=pd.read_excel(r'C:\\Users\\A803377\\OneDrive - Solenis LLC\\Documents\\TREK-All-Learners2.xlsx')\n",
    "df = pd.merge(df, df1,on=['Last Name','First Name','Username','Date Created','Group',\n",
    "                              'SubGroups','Coaches','Status','Coach First Name','Coach Last Name','Role','Is Coach'], how=\"left\")\n",
    "\n",
    "#Setting the Index To Required Columns \n",
    "df = df.set_index(['Last Name','First Name','Username','Date Created','Group','SubGroups','Coaches','Status','Coach First Name','Coach Last Name','Role','Is Coach'\n",
    "])\n",
    "\n",
    "#Adding 1st level name to Score,LearningPath and Status\n",
    "df.columns = ['COURSESCORE ' + col if 'Score' in col.split() else col for col in df.columns]\n",
    "df.columns = ['COURSELEARNINGPATH ' + col if 'Path' in col.split() else col for col in df.columns]\n",
    "df.columns = ['COURSESTATUS ' + col if 'Status' in col.split() else col for col in df.columns]\n",
    "\n",
    "#Creating 1st level name for unwanted columns \n",
    "df.columns = ['COURSEDrop ' + col if 'Artifacts?' in col.split() else col for col in df.columns]\n",
    "df.columns = ['COURSEDrop ' + col if 'Followup?' in col.split() else col for col in df.columns]\n",
    "df.columns = ['COURSEDrop ' + col if 'Link(s)' in col.split() else col for col in df.columns]\n",
    "\n",
    "#Creating MultiLevel Index\n",
    "df.columns = df.columns.str.partition(' ').droplevel(1)\n",
    "\n",
    "#Dropping unwanted Columns \n",
    "df= df.drop(['COURSEDrop'], axis = 1)\n",
    "\n",
    "#Creating Dataframes For Score,Learning and Status\n",
    "df_Score= df.drop(['COURSELEARNINGPATH','COURSESTATUS'], axis = 1)\n",
    "df_Learning= df.drop(['COURSESCORE','COURSESTATUS'], axis = 1)\n",
    "df_Status= df.drop(['COURSELEARNINGPATH','COURSESCORE'], axis = 1)\n",
    "\n",
    "#Stacking the Dataframes\n",
    "df_Score = df_Score.stack(1).reset_index().rename(columns={'level_12':'COURSESCORE','COURSESCORE':'SCORE_VALUE'})\n",
    "df_Learning = df_Learning.stack(1).reset_index().rename(columns={'level_12':'COURSELEARNINGPATH','COURSELEARNINGPATH':'LEARNINGPATH_VALUE'})\n",
    "df_Status = df_Status.stack(1).reset_index().rename(columns={'level_12':'COURSESTATUS','COURSESTATUS':'STATUS_Value'})\n",
    "\n",
    "#Creating Course_ID to Use it in Meargning the Dataframes \n",
    "df_Score['Course_ID'] = df_Score['COURSESCORE'].apply(lambda x: x.split(':')[0])\n",
    "df_Score['Course_ID'] = df_Score['Course_ID'].apply(lambda x: x.split('.')[0])\n",
    "df_Learning['Course_ID'] = df_Learning['COURSELEARNINGPATH'].apply(lambda x: x.split(':')[0])\n",
    "df_Learning['Course_ID'] = df_Learning['Course_ID'].apply(lambda x: x.split('.')[0])\n",
    "df_Status['Course_ID'] = df_Status['COURSESTATUS'].apply(lambda x: x.split(':')[0])\n",
    "df_Status['Course_ID'] = df_Status['Course_ID'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "# Merge List \n",
    "Mergelist=['Last Name','First Name','Username','Date Created','Group','SubGroups','Coaches','Status','Coach First Name','Coach Last Name','Role','Is Coach','Course_ID']\n",
    "#Merging the DataFrames \n",
    "df_merged = pd.merge(pd.merge(df_Score, df_Learning,on= Mergelist, how=\"left\"),df_Status,on= Mergelist,how=\"left\")\n",
    "#Update Date \n",
    "df_merged['Created_date']= pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "#Adding Blank Columns \n",
    "df_merged[\"GROUP2\"] = \"\"\n",
    "df_merged[\"RESULT\"] = \"\"\n",
    "df_merged[\"COURSE_NAME\"] = \"\"\n",
    "df_merged[\"SALESOFFICE\"] = \"\"\n",
    "#Droping Course_ID\n",
    "#df_merged=df_merged.drop(['Course_ID'], axis = 1)\n",
    "#Reindexing to match SQL Format\n",
    "df_merged = df_merged.reindex(['Last Name','First Name','Username','Group','SubGroups','Coaches','Status','Coach First Name','Coach Last Name','Role','Is Coach','COURSE_NAME','RESULT','GROUP2','Created_date','SALESOFFICE','Date Created','COURSESCORE','SCORE_VALUE','COURSESTATUS','STATUS_Value','COURSELEARNINGPATH','LEARNINGPATH_VALUE'], axis=1)\n",
    "#Changing Column Name to Match SQL FORMAT\n",
    "df_merged = df_merged.rename(columns = {\"Date Created\":\"DATECREATED\"})\n",
    "#Changing dtype to object\n",
    "df_merged['DATECREATED'] = df_merged['DATECREATED'].dt.strftime('%m-%d-%Y')\n",
    "#df_merged['DATECREATED'] = df_merged['DATECREATED'].astype(object)\n",
    "#df_merged['SCORE_VALUE'] = df_merged['SCORE_VALUE'].astype(object)\n",
    "df_test=df_merged.head(20)\n",
    "print('Data Retrived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = ('Driver={SQL Server};''SERVER=NAAZUREEDWS01;''Database=TableauDB;''Trusted_Connection=yes;')\n",
    "connection_uri = f\"mssql+pyodbc:///?odbc_connect={urllib.parse.quote_plus(connection_string)}\"\n",
    "engine = sa.create_engine(connection_uri,echo=False)\n",
    "engine.fast_executemany = True\n",
    " #Deleting existing data in SQL Table:-\n",
    "#with engine.begin() as conn:\n",
    "    #conn.execute(sa.text(\"DELETE FROM TableauDb.dbo.FinalTrekAssessmentData\"))\n",
    "\n",
    "# upload the DataFrame\n",
    "df_merged[0:20].to_sql('FinalTrekAssessmentData', engine, if_exists=\"append\", index=False)\n",
    "print(\"Update Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2eee7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "conn = cnxn = pyodbc.connect('Driver=SQL Server;Server=NAAZUREEDWS01;Database=TableauDB;Trusted_Connection=yes;')\n",
    "crsr.fast_executemany = True\n",
    "with open (r'C:\\Users\\A803377\\OneDrive - Solenis LLC\\Documents\\\\Trektest.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    columns = next(reader) \n",
    "    #query = 'insert into [dbo].[FinalTrekAssessmentData]({[0]}) values ({1})'\n",
    "    #query = query.format('],['.join(columns), ','.join('?' * len(columns)))\n",
    "    query = 'insert into [dbo].[FinalTrekAssessmentData]([Last Name],[First Name],[Username],[Group],[SubGroups],[Coaches],[Status],[Coach First Name],[Coach Last Name],[Role],[Is Coach],[COURSE_NAME],[RESULT],[GROUP2],[Created_date],[SALESOFFICE],[DATECREATED],[COURSESCORE],[SCORE_VALUE],[COURSESTATUS],[STATUS_Value],[COURSELEARNINGPATH],[LEARNINGPATH_VALUE]) values (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)'\n",
    "    cursor = conn.cursor()\n",
    "    for data in reader:\n",
    "        cursor.execute(query, data)\n",
    "    cursor.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
